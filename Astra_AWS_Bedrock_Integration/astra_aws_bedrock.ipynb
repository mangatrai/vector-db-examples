{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6715bc2b",
   "metadata": {
    "id": "6715bc2b"
   },
   "source": [
    "# Vector Similarity Astra-Bedrock Search QA Quickstart\n",
    "\n",
    "Set up a simple Question-Answering system with LangChain and Amazon Bedrock, using Astra DB as the Vector Database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d9b70",
   "metadata": {
    "id": "761d9b70"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "Make sure you have a vector-capable Astra database (get one for free at [astra.datastax.com](https://astra.datastax.com)):\n",
    "\n",
    "- You will be asked to provide the **Database ID** for your Astra DB instance (see [here](https://awesome-astra.github.io/docs/pages/astra/faq/#where-should-i-find-a-database-identifier) for details);\n",
    "- Ensure you have an **Access Token** for your database with role _Database Administrator_ (see [here](https://awesome-astra.github.io/docs/pages/astra/create-token/) for details).\n",
    "\n",
    "Likewise, you will need the credentials to your Amazon Web Services identity, with access to **Amazon Bedrock**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18548e31",
   "metadata": {
    "id": "18548e31"
   },
   "source": [
    "## Set up your Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042f832e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "042f832e",
    "outputId": "26248b8c-f49e-480b-e5f3-598e5bec666d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet \\\n",
    "  \"cassio>=0.1.3\" \\\n",
    "  \"langchain==0.0.249\" \\\n",
    "  \"boto3==1.28.62\" \\\n",
    "  \"botocore==1.31.62\" \\\n",
    "  \"cohere==4.37\" \\\n",
    "  \"openai==1.3.7\" \\\n",
    "  \"tiktoken==0.5.2\" \\\n",
    "  \"awscli==1.29.62\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c840842",
   "metadata": {
    "id": "6c840842"
   },
   "source": [
    "## Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b243d1b4",
   "metadata": {
    "id": "b243d1b4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "import boto3\n",
    "import cassio\n",
    "\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.vectorstores import Cassandra\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccce0c2",
   "metadata": {
    "id": "fccce0c2"
   },
   "source": [
    "## Astra DB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0a92b-f9ce-4810-a8ef-5741b2449b18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9b0a92b-f9ce-4810-a8ef-5741b2449b18",
    "outputId": "4af9cdff-0e7b-46e3-e55f-659ec6a60159",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ASTRA_DB_ID = input(\"Enter your Astra DB ID ('0123abcd-'):\")\n",
    "ASTRA_DB_APPLICATION_TOKEN = getpass(\"Enter your Astra DB Token ('AstraCS:...'):\")\n",
    "ASTRA_DB_KEYSPACE = input(\"Enter your keyspace name (optional, default keyspace used if not provided):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a066f378-8fdb-4d4b-a7b1-bf685fbfd413",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a066f378-8fdb-4d4b-a7b1-bf685fbfd413",
    "outputId": "0c25a268-1f38-42a6-e057-a4f0ae2c1b00",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cassio.init(\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    database_id=ASTRA_DB_ID,\n",
    "    keyspace=ASTRA_DB_KEYSPACE if ASTRA_DB_KEYSPACE else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c674f1",
   "metadata": {
    "id": "33c674f1"
   },
   "source": [
    "## AWS Credentials Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219cb02-f955-4fb3-85af-3f149868958a",
   "metadata": {
    "id": "3219cb02-f955-4fb3-85af-3f149868958a"
   },
   "source": [
    "_Note_: in the following cells you will be asked to explicitly provide the credentials to your AWS account. These are set as environment variables for usage by the subsequent `boto3` calls. Please refer to [boto3's documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html) on the possible ways to supply your credentials in a more production-like environment.\n",
    "\n",
    "In particular, if you are running this notebook in **Amazon SageMaker Studio**, please note that it is sufficient to add the Bedrock policy to your SageMaker role, as outlined at [this link](https://github.com/aws-samples/amazon-bedrock-workshop#enable-aws-iam-permissions-for-bedrock), to access the Bedrock services. In that case you can skip the following three setup cells.\n",
    "\n",
    "I was able to make role work so i didn't need to set next three cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb76ea",
   "metadata": {
    "id": "ccbb76ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input your AWS Access Key ID\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass(\"Your AWS Access Key ID:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c873d",
   "metadata": {
    "id": "f93c873d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input your AWS Secret Access Key\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass(\"Your AWS Secret Access Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737249f5",
   "metadata": {
    "id": "737249f5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input your AWS Session Token\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = getpass(\"Your AWS Session Token:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388ac1d",
   "metadata": {
    "id": "4388ac1d"
   },
   "source": [
    "## Set up AWS Bedrock objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65c46f0",
   "metadata": {
    "id": "d65c46f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", \"us-east-1\")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",\n",
    "                                       client=bedrock_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9f48b",
   "metadata": {
    "id": "29d9f48b"
   },
   "source": [
    "## Set up the Vector Store\n",
    "\n",
    "This command will create a suitable table in your database if it does not exist yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d9f48c",
   "metadata": {
    "id": "29d9f48c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_store = Cassandra(\n",
    "    embedding=bedrock_embeddings,\n",
    "    table_name=\"shakespeare_act5\",\n",
    "    session=None,  # <-- meaning: use the global defaults from cassio.init()\n",
    "    keyspace=None,  # <-- meaning: use the global defaults from cassio.init()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af24199",
   "metadata": {
    "id": "6af24199"
   },
   "source": [
    "## Populate the database\n",
    "\n",
    "Add lines for the text of \"Romeo and Astra\", Scene 5, Act 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dab5114",
   "metadata": {
    "id": "1dab5114",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 75985  100 75985    0     0   345k      0 --:--:-- --:--:-- --:--:--  346k\n"
     ]
    }
   ],
   "source": [
    "# retrieve the text of a scene from act 5 of Romeo and Astra.\n",
    "# Juliet's name was changed to Astra to prevent the LLM from \"cheating\" when providing an answer.\n",
    "! mkdir -p \"texts\"\n",
    "! curl \"https://raw.githubusercontent.com/awesome-astra/docs/main/docs/pages/aiml/aws/bedrock_resources/romeo_astra.json\" \\\n",
    "    --output \"texts/romeo_astra.json\"\n",
    "input_lines = json.load(open(\"texts/romeo_astra.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6b732",
   "metadata": {
    "id": "4cb6b732"
   },
   "source": [
    "Next, you'll populate the database with the lines from the play.\n",
    "This can take a couple of minutes, please be patient.  In total there are 321 lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bae5520",
   "metadata": {
    "id": "7bae5520",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 321 documents ... Done.\n"
     ]
    }
   ],
   "source": [
    "input_documents = []\n",
    "\n",
    "for input_line in input_lines:\n",
    "    if (input_line[\"ActSceneLine\"] != \"\"):\n",
    "        (act, scene, line) = input_line[\"ActSceneLine\"].split(\".\")\n",
    "        location = \"Act {}, Scene {}, Line {}\".format(act, scene, line)\n",
    "        metadata = {\"act\": act, \"scene\": scene, \"line\": line}\n",
    "    else:\n",
    "        location = \"\"\n",
    "        metadata = {}\n",
    "    quote_input = \"{} : {} : {}\".format(location, input_line[\"Player\"], input_line[\"PlayerLine\"])\n",
    "    input_document = Document(page_content=quote_input, metadata=metadata)\n",
    "    input_documents.append(input_document)\n",
    "\n",
    "print(f\"Adding {len(input_documents)} documents ... \", end=\"\")\n",
    "vector_store.add_documents(documents=input_documents, batch_size=50)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162c2d1-188e-43f0-b1c3-342b80641060",
   "metadata": {
    "id": "d162c2d1-188e-43f0-b1c3-342b80641060"
   },
   "source": [
    "## Answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5332b838-6c1f-40f4-a29e-2b2d0250f408",
   "metadata": {
    "id": "5332b838-6c1f-40f4-a29e-2b2d0250f408",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template_str = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67346b-d5ca-433d-858e-5c21397f9de5",
   "metadata": {
    "id": "ea67346b-d5ca-433d-858e-5c21397f9de5",
    "tags": []
   },
   "source": [
    "We choose to use the following LLM model (see [this page](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html#model-parameters-general) for more info):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8b2ee0-f9bf-4ada-8fde-7d917d89c6fa",
   "metadata": {
    "id": "ee8b2ee0-f9bf-4ada-8fde-7d917d89c6fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"anthropic.claude-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4081fd78-1710-4a42-a942-a14f652c854d",
   "metadata": {
    "id": "4081fd78-1710-4a42-a942-a14f652c854d"
   },
   "source": [
    "Here the question-answering function is set up, implementing the RAG pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e82ef49-ffec-4429-bcc2-ea09f50333cd",
   "metadata": {
    "id": "4e82ef49-ffec-4429-bcc2-ea09f50333cd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "req_accept = \"application/json\"\n",
    "req_content_type = \"application/json\"\n",
    "\n",
    "# This, created from the vector store, will fetch the top relevant documents given a text query\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "def answer_question(question: str, verbose: bool = False) -> str:\n",
    "    if verbose:\n",
    "        print(f\"\\n[answer_question] Question: {question}\")\n",
    "    # Retrieval of the most relevant stored documents from the vector store:\n",
    "    context_docs = retriever.get_relevant_documents(question)\n",
    "    context = \"\\n\".join(doc.page_content for doc in context_docs)\n",
    "    if verbose:\n",
    "        print(\"\\n[answer_question] Context:\")\n",
    "        print(context)\n",
    "    # Filling the prompt template with the current values\n",
    "    llm_prompt_str = prompt.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "    )\n",
    "    # Invocation of the Amazon Bedrock LLM for text completion -- ultimately obtaining the answer\n",
    "    llm_body = json.dumps({\"prompt\": llm_prompt_str, \"max_tokens_to_sample\": 500})\n",
    "    llm_response = bedrock_runtime.invoke_model(\n",
    "        body=llm_body,\n",
    "        modelId=model_id,\n",
    "        accept=req_accept,\n",
    "        contentType=req_content_type,\n",
    "    )\n",
    "    llm_response_body = json.loads(llm_response[\"body\"].read())\n",
    "    answer = llm_response_body[\"completion\"].strip()\n",
    "    if verbose:\n",
    "        print(f\"\\n[answer_question] Answer: {answer}\\n\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599d8856-921e-4bf4-8979-ff54b13de6d5",
   "metadata": {
    "id": "599d8856-921e-4bf4-8979-ff54b13de6d5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Based on the provided context, it seems that Astra and Romeo both die in the story. The watchman finds Astra dead in the vault, and Balthasar brings news to Romeo that Astra has died. Romeo then goes to the vault to die and lie with Astra. So the context indicates that both Astra and Romeo die.\n"
     ]
    }
   ],
   "source": [
    "my_answer = answer_question(\"Who dies in the story?\")\n",
    "print(\"=\" * 60)\n",
    "print(my_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e68ed05-bc94-4f5e-8311-6784c75808ff",
   "metadata": {
    "id": "599d8856-921e-4bf4-8979-ff54b13de6d5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Based on the context provided, Astra seems to be a woman that Romeo was in love with, who died. Lines like \"For here lies Astra, and her beauty makes\" and \"As that of true and faithful Astra\" suggest she was beautiful and Romeo's love interest. Other lines mention her death and pining for someone other than Tybalt, indicating she is a separate character from Juliet. However, without more context about the overall story and characters, I cannot conclusively say who Astra is. The provided information suggests she is a love interest of Romeo who died, but I do not have enough context to definitively identify her role and relationship to other characters.\n"
     ]
    }
   ],
   "source": [
    "my_answer = answer_question(\"Who is Astra?\")\n",
    "print(\"=\" * 60)\n",
    "print(my_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71cc88-61e3-42e5-802b-4ba4eaa795b4",
   "metadata": {
    "id": "db71cc88-61e3-42e5-802b-4ba4eaa795b4"
   },
   "source": [
    "Let's take a look at the RAG process piece-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbeaf2d-f589-4d04-8447-4b876375f5b1",
   "metadata": {
    "id": "6fbeaf2d-f589-4d04-8447-4b876375f5b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[answer_question] Question: In what era does this story happen?\n",
      "\n",
      "[answer_question] Context:\n",
      "Act 5, Scene 3, Line 18 : PARIS : The boy gives warning something doth approach.\n",
      "Act 5, Scene 3, Line 232 : PRINCE : Bring forth the parties of suspicion.\n",
      "Act 5, Scene 3, Line 289 : PRINCE : Where is the county's page, that raised the watch?\n",
      "Act 5, Scene 3, Line 176 : First Watchman : [Within]  Lead, boy: which way?\n",
      "Act 5, Scene 3, Line 192 : First Watchman : Hold him in safety, till the prince come hither.\n",
      "\n",
      "[answer_question] Answer: Based on the context provided, I do not have enough information to determine the era or time period that this story takes place in. The dialogue mentions a prince and pages, but without more contextual clues about the setting, technology, culture, etc., I cannot confidently identify the era.\n",
      "\n",
      "============================================================\n",
      "Based on the context provided, I do not have enough information to determine the era or time period that this story takes place in. The dialogue mentions a prince and pages, but without more contextual clues about the setting, technology, culture, etc., I cannot confidently identify the era.\n"
     ]
    }
   ],
   "source": [
    "my_answer = answer_question(\"In what era does this story happen?\", verbose=True)\n",
    "print(\"=\" * 60)\n",
    "print(my_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ba03a-66d1-47fe-9a8e-6b2713ddd0f9",
   "metadata": {
    "id": "715ba03a-66d1-47fe-9a8e-6b2713ddd0f9"
   },
   "source": [
    "### Interactive QA session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe0df9c-b24d-4f35-aee4-8bef2dd1e1a6",
   "metadata": {
    "editable": true,
    "id": "9fe0df9c-b24d-4f35-aee4-8bef2dd1e1a6",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a question (empty to quit): tell me learning from the story\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer ==> Based on the provided context, I don't have enough information to summarize the key learnings from the full story. The lines provided are fragmented and don't provide a clear picture of the overall narrative or themes. Without more context, I cannot confidently identify the main takeaways or lessons.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a question (empty to quit): who is the main character\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer ==> Based on the provided context, I don't have enough information to determine the main character. The lines are spoken by multiple characters (Page, Friar Laurence, First Watchman, Balthasar) without indicating who the protagonist is. Without more context about the overall story and characters, I don't know who the main character is.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a question (empty to quit): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User, AI exeunt]\n"
     ]
    }
   ],
   "source": [
    "user_question = \"\"\n",
    "while True:\n",
    "    user_question = input(\"Enter a question (empty to quit):\").strip()\n",
    "    if user_question:\n",
    "        print(f\"Answer ==> {answer_question(user_question)}\")\n",
    "    else:\n",
    "        print(\"[User, AI exeunt]\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c2d97",
   "metadata": {
    "id": "f31c2d97"
   },
   "source": [
    "## Additional resources\n",
    "\n",
    "To learn more about Amazon Bedrock, visit this page: [Introduction to Amazon Bedrock](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/introduction-to-bedrock)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
