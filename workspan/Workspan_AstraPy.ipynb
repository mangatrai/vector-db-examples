{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6715bc2b",
      "metadata": {
        "id": "6715bc2b"
      },
      "source": [
        "# Astra DB with AstraPy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f6e9609-7293-4d46-a63a-5e0986581d70",
      "metadata": {
        "id": "9f6e9609-7293-4d46-a63a-5e0986581d70"
      },
      "source": [
        "Learn how to use your Astra DB database with AstraPy.\n",
        "\n",
        "In this quickstart, you'll create a vector collection, store a few documents on it, and run **vector searches** on it.\n",
        "\n",
        "_Prerequisites:_ Make sure you have an Astra DB instance and get ready to supply the corresponding *Token* and the *API Endpoint*\n",
        "(read more [here](https://docs.datastax.com/en/astra/home/astra.html))."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14da74b6",
      "metadata": {
        "id": "14da74b6"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042f832e",
      "metadata": {
        "id": "042f832e"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade astrapy openai langchain cassio tiktoken gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84026946",
      "metadata": {
        "id": "84026946"
      },
      "source": [
        "### Import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b15d1a4",
      "metadata": {
        "id": "5b15d1a4"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "from getpass import getpass\n",
        "\n",
        "from astrapy.db import AstraDB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968c5070-24a1-4cf3-a923-2478ceaa2e37",
      "metadata": {
        "id": "968c5070-24a1-4cf3-a923-2478ceaa2e37"
      },
      "source": [
        "### Provide database credentials\n",
        "\n",
        "These are the connection parameters on your Astra dashboard. Example values:\n",
        "\n",
        "- API Endpoint: `https://01234567-89ab-cdef-0123-456789abcdef-us-east1.apps.astra.datastax.com`\n",
        "- Token: `AstraCS:6gBhNmsk135...`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9a7b18-e7a8-466e-8785-2becc94017fb",
      "metadata": {
        "id": "0c9a7b18-e7a8-466e-8785-2becc94017fb"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_API_ENDPOINT = \"\"\n",
        "ASTRA_DB_APPLICATION_TOKEN = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"\""
      ],
      "metadata": {
        "id": "Op73MZCTkC_6"
      },
      "id": "Op73MZCTkC_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "485d5347",
      "metadata": {
        "id": "485d5347"
      },
      "source": [
        "## Create a collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6429f29a",
      "metadata": {
        "id": "6429f29a"
      },
      "source": [
        "### Create the client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971edbec",
      "metadata": {
        "id": "971edbec"
      },
      "outputs": [],
      "source": [
        "astra_db = AstraDB(\n",
        "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
        "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
        "    namespace='workspan'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d51223",
      "metadata": {
        "id": "13d51223"
      },
      "source": [
        "### Create the collection\n",
        "\n",
        "The `create_collection` method results in a new collection on your database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "895ae303-8e47-46ae-94b8-6d2e1e2f1113",
      "metadata": {
        "id": "895ae303-8e47-46ae-94b8-6d2e1e2f1113"
      },
      "outputs": [],
      "source": [
        "collection = astra_db.create_collection(\"workspan_collection\", dimension=1536)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "116596b5-e199-4869-9085-87a0af281afc",
      "metadata": {
        "id": "116596b5-e199-4869-9085-87a0af281afc"
      },
      "source": [
        "Here, `dimension` is the vector dimension (or \"size\", i.e. how many numeric components your vector will have).\n",
        "\n",
        "We choose a very low number in this example for demonstration purposes, but actual embedding vectors usually are much longer.\n",
        "\n",
        "_Note:_ In case it exists already and the parameters match, this method does just return the collection -- you will get an error, instead, if you try to create a collection with the same name but a different configuration (such as a mismatching dimension)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d6effcf",
      "metadata": {
        "id": "4d6effcf"
      },
      "source": [
        "## Insert documents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b012402",
      "metadata": {
        "id": "6b012402"
      },
      "source": [
        "When working with vector stores, your documents can have arbitrary fields, as long as you use only letters, digits and the `_` (underscore) character, preferrably sticking to `snake_case`, in their name.\n",
        "\n",
        "In particular, note the reserved dollar sign in the field names `$vector` and `$similarity`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
        ")\n",
        "\n",
        "embedding_model_name = \"text-embedding-ada-002\""
      ],
      "metadata": {
        "id": "LQnGiyS8dWBD"
      },
      "id": "LQnGiyS8dWBD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29a6f70",
      "metadata": {
        "id": "c29a6f70"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "# record #1\n",
        "\n",
        "uuid_rec1 = str(uuid.uuid1())\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Michael, confirmed deprioritize. From Anjaney, account executive interest to schedule meeting - Anjaney to schedule call with Nirav/Amy on R&D.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "Next Step:\n",
        "08/16/2023 : Review partner information updates and update opportunity details. 8/17(LR) - connecting with Partner to offer co-sell support\n",
        "\n",
        "Next Step History:\n",
        "null;08/16/2023 : Review partner information updates and update opportunity details.;08/16/2023 : Review partner information updates and update opportunity details. 8/17(LR) - connecting with Partner to offer co-sell support\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-7202838a', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence_rec1 = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "\n",
        "vector_embedding_rec1 = client.embeddings.create(\n",
        "        input=next_step_and_cadence_rec1,\n",
        "        model=embedding_model_name,\n",
        "    ).data[0].embedding\n",
        "\n",
        "\n",
        "# record #2\n",
        "\n",
        "uuid_rec2 = str(uuid.uuid1())\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Autumn, send recording of last call and our discussed inputs from demo 8/28. Ramesh will provide to Caroline by early next week (of 9/11).\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "REVIEW TECH & Economic Proposal\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-8a038b8a', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence_rec2 = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "\n",
        "vector_embedding_rec2 = client.embeddings.create(\n",
        "        input=next_step_and_cadence_rec2,\n",
        "        model=embedding_model_name,\n",
        "    ).data[0].embedding\n",
        "\n",
        "\n",
        "# record #3\n",
        "\n",
        "uuid_rec3 = str(uuid.uuid1())\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "Joint sync set for 9/7. Enablement session to follow + in person account mapping. Caroline / Michael to begin coordinating. EAI presence\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "07/05/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-8a3b0348', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence_rec3 = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "\n",
        "vector_embedding_rec3 = client.embeddings.create(\n",
        "        input=next_step_and_cadence_rec3,\n",
        "        model=embedding_model_name,\n",
        "    ).data[0].embedding\n",
        "\n",
        "\n",
        "# record #4\n",
        "\n",
        "uuid_rec4 = str(uuid.uuid1())\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Caroline, user community engaged to respond to questions. @Dataiku - How can we get initial data from user community/pull together PoV for client? Action (Asan/Ken (sp?)): In-person outreach to Deloitte users and follow-up to 5 responses received.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "null;06/20/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support;07/05/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-8a7128a3', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence_rec4 = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "\n",
        "vector_embedding_rec4 = client.embeddings.create(\n",
        "        input=next_step_and_cadence_rec4,\n",
        "        model=embedding_model_name,\n",
        "    ).data[0].embedding\n",
        "\n",
        "\n",
        "# record #5\n",
        "\n",
        "uuid_rec5 = str(uuid.uuid1())\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Propsal did not go thru. No budget Left. Negative.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "No further follow up required.\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS101', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-8a7128a4', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence_rec5 = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "\n",
        "vector_embedding_rec5 = client.embeddings.create(\n",
        "        input=next_step_and_cadence_rec5,\n",
        "        model=embedding_model_name,\n",
        "    ).data[0].embedding\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe944cf0",
      "metadata": {
        "id": "fe944cf0"
      },
      "source": [
        "### Insert multiple documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b5c026",
      "metadata": {
        "id": "c9b5c026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43775f38-c9d3-4b91-e536-2032a551cd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': {'insertedIds': ['f554f99a-8be6-11ee-ad16-0242ac1c000c', 'f578fa70-8be6-11ee-ad16-0242ac1c000c', 'f593e664-8be6-11ee-ad16-0242ac1c000c', 'f5ab0830-8be6-11ee-ad16-0242ac1c000c', 'f5c12480-8be6-11ee-ad16-0242ac1c000c']}}\n"
          ]
        }
      ],
      "source": [
        "v_doc_list = [\n",
        "    {\n",
        "        \"_id\": uuid_rec1,\n",
        "        'customer_id': 'CUS100',\n",
        "        'partner_id': 'AWS',\n",
        "        'opportunity_id': 'WS-7202838a',\n",
        "        'customer_name': 'Teradyne, Inc.',\n",
        "        \"description\": next_step_and_cadence_rec1,\n",
        "        \"$vector\": vector_embedding_rec1,\n",
        "    },\n",
        "    {\n",
        "        \"_id\": uuid_rec2,\n",
        "        'customer_id': 'CUS100',\n",
        "        'partner_id': 'AWS',\n",
        "        'opportunity_id': 'WS-8a038b8a',\n",
        "        'customer_name': 'Teradyne, Inc.',\n",
        "        \"description\": next_step_and_cadence_rec2,\n",
        "        \"$vector\": vector_embedding_rec2,\n",
        "    },\n",
        "    {\n",
        "        \"_id\": uuid_rec3,\n",
        "        'customer_id': 'CUS100',\n",
        "        'partner_id': 'AWS',\n",
        "        'opportunity_id': 'WS-8a3b0348',\n",
        "        'customer_name': 'Teradyne, Inc.',\n",
        "        \"description\": next_step_and_cadence_rec3,\n",
        "        \"$vector\": vector_embedding_rec3,\n",
        "    },\n",
        "    {\n",
        "        \"_id\": uuid_rec4,\n",
        "        'customer_id': 'CUS100',\n",
        "        'partner_id': 'AWS',\n",
        "        'opportunity_id': 'WS-8a7128a3',\n",
        "        'customer_name': 'Teradyne, Inc.',\n",
        "        \"description\": next_step_and_cadence_rec4,\n",
        "        \"$vector\": vector_embedding_rec4,\n",
        "    },\n",
        "    {\n",
        "        \"_id\": uuid_rec5,\n",
        "        'customer_id': 'CUS101',\n",
        "        'partner_id': 'AWS',\n",
        "        'opportunity_id': 'WS-8a7128a4',\n",
        "        'customer_name': 'Cisco, Inc.',\n",
        "        'AWS Partner Sales Stage' : 'Technical Validation',\n",
        "        \"description\": next_step_and_cadence_rec5,\n",
        "        \"$vector\": vector_embedding_rec5,\n",
        "    },\n",
        "]\n",
        "\n",
        "response = collection.insert_many(v_doc_list)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c13cfc42",
      "metadata": {
        "id": "c13cfc42"
      },
      "source": [
        "## Find documents\n",
        "\n",
        "Find by `opportunity_id`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f312b0ab",
      "metadata": {
        "id": "f312b0ab"
      },
      "outputs": [],
      "source": [
        "document = collection.find_one(filter={\"opportunity_id\":\"WS-8a7128a4\"})\n",
        "print(document)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c281d57-6149-4dc7-b6b8-419bc1e6e8b2",
      "metadata": {
        "id": "1c281d57-6149-4dc7-b6b8-419bc1e6e8b2"
      },
      "source": [
        "Find by any (non-vector) filter clause:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08302258",
      "metadata": {
        "id": "08302258"
      },
      "source": [
        "### Find by vector similarity\n",
        "\n",
        "By default, the `$similarity` field is returned with each document (note the decreasing order):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a3c1a8",
      "metadata": {
        "id": "a8a3c1a8"
      },
      "outputs": [],
      "source": [
        "query_vector = client.embeddings.create(\n",
        "                    input=\"What are the next steps?\",\n",
        "                    model=embedding_model_name,\n",
        "                ).data[0].embedding\n",
        "\n",
        "documents = collection.vector_find(query_vector, limit=5)\n",
        "for document in documents:\n",
        "    print(f\"\\n{document}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966ae2b7-62bb-45d6-9c63-ee5a070d7ea8",
      "metadata": {
        "id": "966ae2b7-62bb-45d6-9c63-ee5a070d7ea8"
      },
      "source": [
        "You can specify which **fields** you'll get back and/or whether you need the **similarity** as well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2849712a-fef3-4ae0-984d-4dd23cb7d2b6",
      "metadata": {
        "id": "2849712a-fef3-4ae0-984d-4dd23cb7d2b6"
      },
      "outputs": [],
      "source": [
        "documents = collection.vector_find(\n",
        "    query_vector,\n",
        "    limit=5,\n",
        "    fields=[\"customer_id\",\"partner_id\",\"opportunity_id\"],  # remember the dollar sign (reserved name)\n",
        "    include_similarity=False,\n",
        ")\n",
        "for document in documents:\n",
        "    print(f\"\\n{document}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c31dbe-263e-4997-b1fa-8be3613ea298",
      "metadata": {
        "id": "42c31dbe-263e-4997-b1fa-8be3613ea298"
      },
      "source": [
        "You can compound with other `filter` clauses, effectively implementing **metadata filtering** on your vector searches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56201b18-9672-46a3-a63c-49b032839706",
      "metadata": {
        "id": "56201b18-9672-46a3-a63c-49b032839706"
      },
      "outputs": [],
      "source": [
        "documents = collection.vector_find(\n",
        "    query_vector,\n",
        "    limit=5,\n",
        "    filter={\"customer_id\": \"CUS100\"},\n",
        ")\n",
        "for document in documents:\n",
        "    print(f\"\\n{document}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c35151b8",
      "metadata": {
        "id": "c35151b8"
      },
      "source": [
        "These options are supported for the `vector_find_one` method as well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87278dda",
      "metadata": {
        "id": "87278dda"
      },
      "outputs": [],
      "source": [
        "fields = [\"description\"]\n",
        "\n",
        "document = collection.vector_find_one(\n",
        "    query_vector,\n",
        "    fields=[\"opportunity_id\"],\n",
        "    include_similarity=True,  # not really necessary since True is the default\n",
        ")\n",
        "print(document)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UI Demo\n",
        "\n",
        "The llm_response_openai method implements the following steps,\n",
        "1.   Generate an OpenAI embedding corresponding to the user's question.\n",
        "2.   Retrieve records from Astra Vector DB based on vector similarity search for the generated embedding.\n",
        "3.   Build a prompt for the Large Language Model (LLM).\n",
        "4.   Generate LLM results based on the prompt."
      ],
      "metadata": {
        "id": "IVYcNdOIw5Bf"
      },
      "id": "IVYcNdOIw5Bf"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_str = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end.\n",
        "                      If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "                      <context>\n",
        "                      {context}\n",
        "                      </context>\n",
        "\n",
        "                      Question: {question}\n",
        "\n",
        "                      Assistant:\"\"\"\n",
        "\n",
        "def llm_response_openai(question: str, verbose: bool = False) -> str:\n",
        "    if verbose:\n",
        "        print(f\"\\n[answer_question] Question: {question}\")\n",
        "    # Retrieval of the most relevant stored documents from the vector store:\n",
        "\n",
        "    query_vector = client.embeddings.create(\n",
        "                    input=question,\n",
        "                    model=embedding_model_name,\n",
        "                ).data[0].embedding\n",
        "\n",
        "    context_docs = collection.vector_find(\n",
        "        query_vector,\n",
        "        limit=5,\n",
        "        fields=[\"description\"],  # remember the dollar sign (reserved name)\n",
        "        include_similarity=False,\n",
        "    )\n",
        "    context = \"\\n\".join(doc['description'] for doc in context_docs)\n",
        "    if verbose:\n",
        "        print(\"\\n[answer_question] Context:\")\n",
        "        print(context)\n",
        "    # Filling the prompt template with the current values\n",
        "    llm_prompt_str = prompt_template_str.format(\n",
        "        context=context,\n",
        "        question=question\n",
        "    )\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the instructions provided to process the information.\"},\n",
        "            {\"role\": \"user\", \"content\": llm_prompt_str}\n",
        "        ]\n",
        "    )\n",
        "    print(response)\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "eZw34foU0Ekw"
      },
      "id": "eZw34foU0Ekw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI - for testing sample queries\n",
        "\n",
        "Sample queries,\n",
        "\n",
        "\n",
        "1.   Can you list the opportunities for 'customer_id': 'CUS100' ?\n",
        "2.   Can you list the opportunities for 'customer_id': 'CUS101' ?\n",
        "3.   What are the next steps for each opportunity for the customer 'customer_id': 'CUS100' ?\n",
        "4.   What are the identified challenges for the customer 'customer_id': 'CUS100' ?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1pLXaIkNzvmy"
      },
      "id": "1pLXaIkNzvmy"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict(message, history):\n",
        "    response = llm_response_openai(message)\n",
        "    return response\n",
        "\n",
        "gr.ChatInterface(predict).launch()"
      ],
      "metadata": {
        "id": "9V7IdCerCHMI"
      },
      "id": "9V7IdCerCHMI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
